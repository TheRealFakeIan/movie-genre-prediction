{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Movie Genre Predictor Analysis \n",
    "\n",
    "## Subject : Romance or Thriller? Movie Genre Prediction from Audio, Visual, and Text Features!\n",
    "\n",
    "## Course Code : COMP 90049\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(r\"C:\\Users\\cyeeh\\OneDrive\\Masters\\2020 Sem 1\\Intro to Machine Learning\\ML Assignment 2\\NEW_data\\data\\train_features.tsv\",sep='\\t')\n",
    "X_valid = pd.read_csv(r\"C:\\Users\\cyeeh\\OneDrive\\Masters\\2020 Sem 1\\Intro to Machine Learning\\ML Assignment 2\\NEW_data\\data\\valid_features.tsv\",sep='\\t')\n",
    "\n",
    "train_labels = pd.read_csv(r\"C:\\Users\\cyeeh\\OneDrive\\Masters\\2020 Sem 1\\Intro to Machine Learning\\ML Assignment 2\\NEW_data\\data\\train_labels.tsv\",sep=\"\\t\")\n",
    "y_valid = pd.read_csv(r\"C:\\Users\\cyeeh\\OneDrive\\Masters\\2020 Sem 1\\Intro to Machine Learning\\ML Assignment 2\\NEW_data\\data\\valid_labels.tsv\",sep=\"\\t\")\n",
    "\n",
    "valid_features = X_valid\n",
    "X_train = train_features\n",
    "y_train = train_labels\n",
    "\n",
    "y_train_genre_only = y_train['genres'].values\n",
    "y_valid_genre_only = y_valid['genres'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the distribution of target values in our training set for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 18 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ellen_de_genres = {}\n",
    "for genre in y_train_genre_only:\n",
    "    if genre not in ellen_de_genres:\n",
    "        ellen_de_genres[genre] = 1\n",
    "    else:\n",
    "        ellen_de_genres[genre] += 1\n",
    "        \n",
    "ellen_de_genres = {k: v for k, v in sorted(ellen_de_genres.items(), key=lambda item: item[1], reverse = True)}\n",
    "ellen_de_genres = {k: v / total for total in (sum(ellen_de_genres.values()),) for k, v in ellen_de_genres.items()}\n",
    "\n",
    "\n",
    "plt.figure(figsize = (18,5))\n",
    "plt.bar(ellen_de_genres.keys(), ellen_de_genres.values(), width = .5, color = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model : Zero-R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero R baseline accuracies\n",
      "--------------------------\n",
      "Baseline Training accuracy: 0.15095419847328245\n",
      "Baseline Validation accuracy: 0.1705685618729097\n"
     ]
    }
   ],
   "source": [
    "# Implement a baseline model - Zero-R\n",
    "#most frequent genre for the true training label is Romance = 791\n",
    "# Expect a training accuracy of 791/5240 = 15%\n",
    "print('Zero R baseline accuracies')\n",
    "print('--------------------------')\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train,y_train_genre_only)\n",
    "predicted_train_genre = dummy_clf.predict(X_train)\n",
    "print('Baseline Training accuracy:',dummy_clf.score(X_train,y_train_genre_only))\n",
    "\n",
    "#Expect a validation accuracy of 17%\n",
    "dummy_clf.fit(X_valid,y_valid_genre_only)\n",
    "predicted_valid_genre = dummy_clf.predict(X_valid)\n",
    "print('Baseline Validation accuracy:',dummy_clf.score(X_valid,y_valid_genre_only))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Functions with Model Training Functions for Textual Features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBmodel_with_countvectorizer(X_train_MNB, X_valid_MNB, y_train_genre_only, y_valid_genre_only):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    v = CountVectorizer()\n",
    "    \n",
    "    train_tag_column = X_train_MNB.pop('tag')\n",
    "    train_tag_column = train_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_train = v.transform(train_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_MNB = pd.concat([X_train_MNB, df1], axis = 1)\n",
    "\n",
    "    train_title_column = X_train_MNB.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_train = v.transform(train_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_MNB = pd.concat([X_train_MNB, df1], axis = 1)\n",
    "\n",
    "    valid_tag_column = X_valid_MNB.pop('tag')\n",
    "    valid_tag_column = valid_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_valid = v.transform(valid_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_MNB = pd.concat([X_valid_MNB, df1], axis = 1)\n",
    "\n",
    "    valid_title_column = X_valid_MNB.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_valid = v.transform(valid_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_MNB = pd.concat([X_valid_MNB, df1], axis = 1)\n",
    "\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn import metrics\n",
    "    X_train_NB = X_train_MNB\n",
    "    X_valid_NB = X_valid_MNB\n",
    "    y_train_genre_only_NB = y_train_genre_only\n",
    "    y_valid_genre_only_NB = y_valid_genre_only\n",
    "    mlt = MultinomialNB()\n",
    "    mlt.fit(X_train_NB, y_train_genre_only_NB)\n",
    "    y_valid_pred_genre_NB = mlt.predict(X_valid_NB)\n",
    "    y_train_pred_genre_NB = mlt.predict(X_train_NB)\n",
    "    print(\"Performing NB without audio and visual based features under CountVectorizer\")\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"Validation Accuracy for MNB:\",metrics.accuracy_score(y_valid_genre_only_NB, y_valid_pred_genre_NB))\n",
    "    print(\"Training Accuracy for MNB:\",metrics.accuracy_score(y_train_genre_only_NB, y_train_pred_genre_NB))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBmodel_with_tfidfvectorizer(X_train_MNB, X_valid_MNB, y_train_genre_only, y_valid_genre_only):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_tag_column = X_train_MNB.pop('tag')\n",
    "    train_tag_column = train_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_train = v.transform(train_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_MNB = pd.concat([X_train_MNB, df1], axis = 1)\n",
    "\n",
    "    train_title_column = X_train_MNB.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_train = v.transform(train_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_MNB = pd.concat([X_train_MNB, df1], axis = 1)\n",
    "\n",
    "    valid_tag_column = X_valid_MNB.pop('tag')\n",
    "    valid_tag_column = valid_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_valid = v.transform(valid_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_MNB = pd.concat([X_valid_MNB, df1], axis = 1)\n",
    "\n",
    "    valid_title_column = X_valid_MNB.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_valid = v.transform(valid_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_MNB = pd.concat([X_valid_MNB, df1], axis = 1)\n",
    "\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn import metrics\n",
    "    X_train_NB = X_train_MNB\n",
    "    X_valid_NB = X_valid_MNB\n",
    "    y_train_genre_only_NB = y_train_genre_only\n",
    "    y_valid_genre_only_NB = y_valid_genre_only\n",
    "    mlt = MultinomialNB()\n",
    "    mlt.fit(X_train_NB, y_train_genre_only_NB)\n",
    "    y_valid_pred_genre_NB = mlt.predict(X_valid_NB)\n",
    "    y_train_pred_genre_NB = mlt.predict(X_train_NB)\n",
    "    print(\"Performing NB without audio and visual based features under TfidfVectorizer\")\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"Validation Accuracy for MNB:\",metrics.accuracy_score(y_valid_genre_only_NB, y_valid_pred_genre_NB))\n",
    "    print(\"Training Accuracy for MNB:\",metrics.accuracy_score(y_train_genre_only_NB, y_train_pred_genre_NB))\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    report_NB = classification_report(y_valid_genre_only_NB, y_valid_pred_genre_NB)\n",
    "    print('\\n')\n",
    "    print(report_NB)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLFNmodel_with_countvectorizer(X_train_NN, X_valid_NN, y_train_genre_only_NN, y_valid_genre_only_NN):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    v = CountVectorizer()\n",
    "    \n",
    "    train_tag_column = X_train_NN.pop('tag')\n",
    "    train_tag_column = train_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_train = v.transform(train_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_NN = pd.concat([X_train_NN, df1], axis = 1)\n",
    "\n",
    "    train_title_column = X_train_NN.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_train = v.transform(train_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_NN = pd.concat([X_train_NN, df1], axis = 1)\n",
    "\n",
    "    valid_tag_column = X_valid_NN.pop('tag')\n",
    "    valid_tag_column = valid_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_valid = v.transform(valid_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_NN = pd.concat([X_valid_NN, df1], axis = 1)\n",
    "\n",
    "    valid_title_column = X_valid_NN.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_valid = v.transform(valid_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_NN = pd.concat([X_valid_NN, df1], axis = 1)\n",
    "    \n",
    "    #normalize data using z-score normalization standardscaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X_train_NN_norma = ss.fit_transform(X_train_NN)\n",
    "    X_valid_NN_norma = ss.transform(X_valid_NN)\n",
    "\n",
    "    import tensorflow.keras as keras\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #first integer-encode our data before one hot encoding using keras\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_genre_only_NN_int = label_encoder.fit_transform(y_train_genre_only_NN)\n",
    "    y_valid_genre_only_NN_int = label_encoder.transform(y_valid_genre_only_NN)\n",
    "\n",
    "    #set the random seed for numpy and tensorflow to ensure reproduceability\n",
    "\n",
    "    np.random.seed(111)\n",
    "    tf.random.set_seed(111)\n",
    "\n",
    "    #convert our class labels using a one hot encoder\n",
    "    y_train_genre_only_NN_onehot = keras.utils.to_categorical(y_train_genre_only_NN_int)\n",
    "    \n",
    "    #implement our neural network\n",
    "    import math\n",
    "    \n",
    "\n",
    "    #determine the number of nodes in the input layer, output layer and hidden layer\n",
    "    feature_count = X_train_NN_norma.shape[1]\n",
    "    label_count = y_train_genre_only_NN_onehot.shape[1]\n",
    "\n",
    "    #calculate the number of nodes in the hidden layer using the formula below\n",
    "    train_instance_count = X_train_NN_norma.shape[0]\n",
    "    alpha = 2\n",
    "    hidden_node_count = math.floor((feature_count + label_count)/2)  \n",
    "\n",
    "\n",
    "\n",
    "    #initialize model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #add hidden layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 50,\n",
    "        input_dim = feature_count,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='sigmoid') \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # add output layer\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            units = label_count,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros',\n",
    "            activation='softmax')\n",
    "        )\n",
    "\n",
    "\n",
    "    # define SGD optimizer\n",
    "    sgd_optimizer = keras.optimizers.SGD(\n",
    "        lr=0.001, decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=sgd_optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "        X_train_NN_norma, y_train_genre_only_NN_onehot,\n",
    "        batch_size=32, epochs=20,\n",
    "        verbose=0, validation_split=0.1\n",
    "    )\n",
    "\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    \n",
    "    print(\"Performing NN without audio and visual based features under CountFVectorizer\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    #evaluate training accuracy for NN\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    #reconvert our integer encoded label into their respective categories\n",
    "    y_train_pred_genre_NN = label_encoder.inverse_transform(y_train_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_train_genre_only_NN == y_train_pred_genre_NN, axis=0)\n",
    "    train_acc = correct_preds / y_train_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Training accuracy for NN: {(train_acc * 100):.2f}')\n",
    "\n",
    "\n",
    "    #evaluate validation accuracy for NN\n",
    "    y_valid_pred_genre_NN_int = model.predict_classes(X_valid_NN_norma, verbose=0)\n",
    "    y_valid_pred_genre_NN = label_encoder.inverse_transform(y_valid_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_valid_genre_only_NN == y_valid_pred_genre_NN, axis=0)\n",
    "    valid_acc = correct_preds / y_valid_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Validation accuracy for NN: {(valid_acc * 100):.2f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLFNmodel_with_tfidfvectorizer(X_train_NN, X_valid_NN, y_train_genre_only_NN, y_valid_genre_only_NN):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_tag_column = X_train_NN.pop('tag')\n",
    "    train_tag_column = train_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_train = v.transform(train_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_NN = pd.concat([X_train_NN, df1], axis = 1)\n",
    "\n",
    "    train_title_column = X_train_NN.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_train = v.transform(train_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_train.toarray(), columns = v.get_feature_names())\n",
    "    X_train_NN = pd.concat([X_train_NN, df1], axis = 1)\n",
    "\n",
    "    valid_tag_column = X_valid_NN.pop('tag')\n",
    "    valid_tag_column = valid_tag_column.map(lambda x:x.replace(',',\" \"))\n",
    "    v.fit(train_tag_column)\n",
    "    transformed_tag_valid = v.transform(valid_tag_column)\n",
    "    df1 = pd.DataFrame(transformed_tag_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_NN = pd.concat([X_valid_NN, df1], axis = 1)\n",
    "\n",
    "    valid_title_column = X_valid_NN.pop('title')\n",
    "    v.fit(train_title_column.values.astype('U'))\n",
    "    transformed_title_valid = v.transform(valid_title_column.values.astype('U'))\n",
    "    df1 = pd.DataFrame(transformed_title_valid.toarray(), columns = v.get_feature_names())\n",
    "    X_valid_NN = pd.concat([X_valid_NN, df1], axis = 1)\n",
    "    \n",
    "    #normalize data using z-score normalization standardscaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X_train_NN_norma = ss.fit_transform(X_train_NN)\n",
    "    X_valid_NN_norma = ss.transform(X_valid_NN)\n",
    "\n",
    "    import tensorflow.keras as keras\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #first integer-encode our data before one hot encoding using keras\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_genre_only_NN_int = label_encoder.fit_transform(y_train_genre_only_NN)\n",
    "    y_valid_genre_only_NN_int = label_encoder.transform(y_valid_genre_only_NN)\n",
    "\n",
    "    #set the random seed for numpy and tensorflow to ensure reproduceability\n",
    "\n",
    "    np.random.seed(111)\n",
    "    tf.random.set_seed(111)\n",
    "\n",
    "    #convert our class labels using a one hot encoder\n",
    "    y_train_genre_only_NN_onehot = keras.utils.to_categorical(y_train_genre_only_NN_int)\n",
    "    \n",
    "    #implement our neural network\n",
    "    import math\n",
    "    \n",
    "\n",
    "    #determine the number of nodes in the input layer, output layer and hidden layer\n",
    "    feature_count = X_train_NN_norma.shape[1]\n",
    "    label_count = y_train_genre_only_NN_onehot.shape[1]\n",
    "\n",
    "    #calculate the number of nodes in the hidden layer using the formula below\n",
    "    train_instance_count = X_train_NN_norma.shape[0]\n",
    "    alpha = 2\n",
    "    hidden_node_count = math.floor((feature_count + label_count)/2)  \n",
    "\n",
    "\n",
    "\n",
    "    #initialize model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #add hidden layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 50,\n",
    "        input_dim = feature_count,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='sigmoid') \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # add output layer\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            units = label_count,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros',\n",
    "            activation='softmax')\n",
    "        )\n",
    "\n",
    "\n",
    "    # define SGD optimizer\n",
    "    sgd_optimizer = keras.optimizers.SGD(\n",
    "        lr=0.001, decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=sgd_optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "        X_train_NN_norma, y_train_genre_only_NN_onehot,\n",
    "        batch_size=32, epochs=20,\n",
    "        verbose=0, validation_split=0.1\n",
    "    )\n",
    "\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    \n",
    "    print(\"Performing NN without audio and visual based features under TfidfVectorizer\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    #evaluate training accuracy for NN\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    #reconvert our integer encoded label into their respective categories\n",
    "    y_train_pred_genre_NN = label_encoder.inverse_transform(y_train_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_train_genre_only_NN == y_train_pred_genre_NN, axis=0)\n",
    "    train_acc = correct_preds / y_train_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Training accuracy for NN: {(train_acc * 100):.2f}')\n",
    "\n",
    "\n",
    "    #evaluate validation accuracy for NN\n",
    "    y_valid_pred_genre_NN_int = model.predict_classes(X_valid_NN_norma, verbose=0)\n",
    "    y_valid_pred_genre_NN = label_encoder.inverse_transform(y_valid_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_valid_genre_only_NN == y_valid_pred_genre_NN, axis=0)\n",
    "    valid_acc = correct_preds / y_valid_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Validation accuracy for NN: {(valid_acc * 100):.2f}')\n",
    "    \n",
    "    from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "    report_NN = classification_report(y_valid_genre_only_NN, y_valid_pred_genre_NN)\n",
    "    print('\\n')\n",
    "    print(report_NN)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a subdataframe without audio and visual features\n",
    "\n",
    "train_text_features = train_features[['title','tag']]\n",
    "valid_text_features = valid_features[['title','tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with Model Training Functions for Numerical features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBmodel_num(X_train_MNB, X_valid_MNB, y_train_genre_only, y_valid_genre_only):\n",
    "    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    X_train_NB = abs(X_train_MNB)\n",
    "    X_valid_NB = abs(X_valid_MNB)\n",
    "    y_train_genre_only_NB = label_encoder.fit_transform(y_train_genre_only)\n",
    "    y_valid_genre_only_NB = label_encoder.transform(y_valid_genre_only)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train_NB, y_train_genre_only_NB)\n",
    "    y_valid_pred_genre_NB = gnb.predict(X_valid_NB)\n",
    "    y_train_pred_genre_NB = gnb.predict(X_train_NB)\n",
    "    print(\"Performing NB with audio and visual based features only\")\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"Validation Accuracy for GNB:\",metrics.accuracy_score(y_valid_genre_only_NB, y_valid_pred_genre_NB))\n",
    "    print(\"Training Accuracy for GNB:\",metrics.accuracy_score(y_train_genre_only_NB, y_train_pred_genre_NB))  \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLFNmodel_num(X_train_NN, X_valid_NN, y_train_genre_only_NN, y_valid_genre_only_NN):\n",
    "    \n",
    "    #normalize data using z-score normalization standardscaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    X_train_NN_norma = ss.fit_transform(X_train_NN)\n",
    "    X_valid_NN_norma = ss.transform(X_valid_NN)\n",
    "\n",
    "    import tensorflow.keras as keras\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import tensorflow as tf\n",
    "\n",
    "    #first integer-encode our data before one hot encoding using keras\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_genre_only_NN_int = label_encoder.fit_transform(y_train_genre_only_NN)\n",
    "    y_valid_genre_only_NN_int = label_encoder.transform(y_valid_genre_only_NN)\n",
    "\n",
    "    #set the random seed for numpy and tensorflow to ensure reproduceability\n",
    "\n",
    "    np.random.seed(111)\n",
    "    tf.random.set_seed(111)\n",
    "\n",
    "    #convert our class labels using a one hot encoder\n",
    "    y_train_genre_only_NN_onehot = keras.utils.to_categorical(y_train_genre_only_NN_int)\n",
    "    \n",
    "    #implement our neural network\n",
    "    import math\n",
    "    \n",
    "\n",
    "    #determine the number of nodes in the input layer, output layer and hidden layer\n",
    "    feature_count = X_train_NN_norma.shape[1]\n",
    "    label_count = y_train_genre_only_NN_onehot.shape[1]\n",
    "\n",
    "    #calculate the number of nodes in the hidden layer using the formula below\n",
    "    train_instance_count = X_train_NN_norma.shape[0]\n",
    "    alpha = 2\n",
    "    hidden_node_count = math.floor((feature_count + label_count)/2)  \n",
    "\n",
    "\n",
    "\n",
    "    #initialize model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #add hidden layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        units = 50,\n",
    "        input_dim = feature_count,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='sigmoid') \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # add output layer\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            units = label_count,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros',\n",
    "            activation='softmax')\n",
    "        )\n",
    "\n",
    "\n",
    "    # define SGD optimizer\n",
    "    sgd_optimizer = keras.optimizers.SGD(\n",
    "        lr=0.001, decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=sgd_optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "        X_train_NN_norma, y_train_genre_only_NN_onehot,\n",
    "        batch_size=32, epochs=20,\n",
    "        verbose=0, validation_split=0.1\n",
    "    )\n",
    "\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    \n",
    "    print(\"Performing NN with audio and visual features only\")\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    #evaluate training accuracy for NN\n",
    "    y_train_pred_genre_NN_int = model.predict_classes(X_train_NN_norma, verbose=0)\n",
    "    #reconvert our integer encoded label into their respective categories\n",
    "    y_train_pred_genre_NN = label_encoder.inverse_transform(y_train_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_train_genre_only_NN == y_train_pred_genre_NN, axis=0)\n",
    "    train_acc = correct_preds / y_train_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Training accuracy for NN: {(train_acc * 100):.2f}')\n",
    "\n",
    "\n",
    "    #evaluate validation accuracy for NN\n",
    "    y_valid_pred_genre_NN_int = model.predict_classes(X_valid_NN_norma, verbose=0)\n",
    "    y_valid_pred_genre_NN = label_encoder.inverse_transform(y_valid_pred_genre_NN_int)\n",
    "    correct_preds = np.sum(y_valid_genre_only_NN == y_valid_pred_genre_NN, axis=0)\n",
    "    valid_acc = correct_preds / y_valid_genre_only_NN.shape[0]\n",
    "\n",
    "    print(f'Validation accuracy for NN: {(valid_acc * 100):.2f}')    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB countvectorizer without audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NB without audio and visual based features under CountVectorizer\n",
      "---------------------------------------------------------------------------\n",
      "Validation Accuracy for MNB: 0.29431438127090304\n",
      "Training Accuracy for MNB: 0.6106870229007634\n"
     ]
    }
   ],
   "source": [
    "NBmodel_with_countvectorizer(train_features[['title','tag']], valid_features[['title','tag']], y_train['genres'].values, y_valid['genres'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB ttfidvectorizer without audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NB without audio and visual based features under TfidfVectorizer\n",
      "---------------------------------------------------------------------------\n",
      "Validation Accuracy for MNB: 0.3210702341137124\n",
      "Training Accuracy for MNB: 0.5305343511450382\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.00      0.00      0.00         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.54      0.37      0.44        38\n",
      "       Crime       0.00      0.00      0.00         5\n",
      " Documentary       0.00      0.00      0.00        18\n",
      "       Drama       0.30      0.58      0.40        43\n",
      "     Fantasy       0.00      0.00      0.00        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.50      0.12      0.20         8\n",
      "     Musical       0.00      0.00      0.00        10\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "     Romance       0.25      0.59      0.35        51\n",
      "      Sci_Fi       0.50      0.75      0.60        16\n",
      "    Thriller       0.34      0.46      0.39        28\n",
      "         War       0.50      0.05      0.09        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.32       299\n",
      "   macro avg       0.16      0.16      0.14       299\n",
      "weighted avg       0.26      0.32      0.25       299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyeeh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "NBmodel_with_tfidfvectorizer(train_features[['title','tag']], valid_features[['title','tag']], y_train['genres'].values, y_valid['genres'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLFN countvectoriser without audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NN without audio and visual based features under CountFVectorizer\n",
      "------------------------------------------------------------------------------\n",
      "Training accuracy for NN: 82.52\n",
      "Validation accuracy for NN: 31.44\n"
     ]
    }
   ],
   "source": [
    "SLFNmodel_with_countvectorizer(train_features[['title','tag']], valid_features[['title','tag']], y_train['genres'].values, y_valid['genres'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLFN tfidfvectoriser without audio and visual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NN without audio and visual based features under TfidfVectorizer\n",
      "------------------------------------------------------------------------------\n",
      "Training accuracy for NN: 83.76\n",
      "Validation accuracy for NN: 33.78\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.00      0.00      0.00         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.36      0.37      0.36        38\n",
      "       Crime       0.17      0.20      0.18         5\n",
      " Documentary       0.25      0.06      0.09        18\n",
      "       Drama       0.34      0.51      0.41        43\n",
      "     Fantasy       0.50      0.33      0.40        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.43      0.38      0.40         8\n",
      "     Musical       0.00      0.00      0.00        10\n",
      "     Mystery       0.40      0.11      0.17        18\n",
      "     Romance       0.35      0.49      0.41        51\n",
      "      Sci_Fi       0.43      0.62      0.51        16\n",
      "    Thriller       0.22      0.39      0.29        28\n",
      "         War       0.40      0.29      0.33        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.34       299\n",
      "   macro avg       0.21      0.21      0.20       299\n",
      "weighted avg       0.31      0.34      0.31       299\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyeeh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "SLFNmodel_with_tfidfvectorizer(train_features[['title','tag']], valid_features[['title','tag']], y_train['genres'].values, y_valid['genres'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating a subdataframe without textual features\n",
    "train_num_features = train_features.drop(['title','tag','year','movieId', 'YTId' ], axis = 1)\n",
    "valid_num_features = valid_features.drop(['title','tag','year','movieId', 'YTId' ], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNB with audio and visual features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NB with audio and visual based features only\n",
      "---------------------------------------------------------------------------\n",
      "Validation Accuracy for GNB: 0.10367892976588629\n",
      "Training Accuracy for GNB: 0.11259541984732824\n"
     ]
    }
   ],
   "source": [
    "NBmodel_num(train_num_features, valid_num_features, y_train['genres'].values, y_valid['genres'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLFN with audio and visual features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NN with audio and visual features only\n",
      "------------------------------------------------------------------------------\n",
      "Training accuracy for NN: 21.77\n",
      "Validation accuracy for NN: 22.07\n"
     ]
    }
   ],
   "source": [
    "SLFNmodel_num(train_num_features, valid_num_features, y_train['genres'].values, y_valid['genres'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
